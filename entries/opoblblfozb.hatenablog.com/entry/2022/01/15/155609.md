---
Title: 最尤法・最大事後確率推定・ベイズ推定について自分の言葉で説明してみる。
Date: 2022-01-15T15:56:09+09:00
URL: https://opoblblfozb.hatenablog.com/entry/2022/01/15/155609
EditURL: https://blog.hatena.ne.jp/opoblblfozb/opoblblfozb.hatenablog.com/atom/entry/13574176438052965135
Draft: true
---
# 本記事の目的
本記事の目的は、機械学習/統計学におけるパラメータ推定の３つの枠組み、最尤法・最大事後確率推定・ベイズ推定について説明することです。とはいえ、このような重要なテーマに関しては、すでに優れた解説が山程あるため、n番煎じにならざるを得ない状況です。したがって、他の良い解説との差分のため、自身が大学院から勉強し始めて理解した過程をたどりながら、なるべく自分の言葉で説明しようと思います。確率分布からお話を始めるので、前提となる知識は、初歩的な確率の概念を理解していることなどです。

# 目次・全体の流れ

- 準備 : 確率分布とは何か？
- 「機械学習」における「機械」とは何か？=統計モデル
- 機械が学習するとは何か？＝統計モデルのパラメタの決定問題
- 学習する方法に何があるのか？=最尤法・最尤推定・ベイズ推定

本記事では、機械学習における「機械」の部分を、統計モデルであると割り切って考えます。この「統計モデル」を理解するために、まず、確率分布の概念を説明します。その後、この「統計モデル」が「学習する」とはどういうことなのかを考え、その後、学習の方法である最尤法・最大事後確率推定法・ベイズ推定法を解説します。

# 準備：確率分布とは何か？
確率分布の概念について、かんたんにおさらいしてから始めます。[wikipedia](https://ja.wikipedia.org/wiki/%E7%A2%BA%E7%8E%87%E5%88%86%E5%B8%83)によると，
```
確率変数に対して、各々の値をとる確率を表したものである。・・・(1)
```
とのことです。それじゃあ、確率変数って何なんだという話になり、[wikipedia](https://ja.wikipedia.org/wiki/%E7%A2%BA%E7%8E%87%E5%A4%89%E6%95%B0)に頼ると、
```
統計学の確率論において、起こりうることがらに割り当てている値（ふつうは実数や整数）を取る変数・・・(2)
```
と出てきます。(1)と(2)から、確率分布とは、
```
起こりうることがらに割り当てている値（ふつうは実数や整数）を取る変数に対して、各々の値をとる確率を表したものである。
```
と言えるわけです。日本語でうまく定義しようとすると、難しいですね！例を見てみましょう。
###### 例１．コインを１枚投げた時にでる面の確率分布
コインを１枚投げたとき、「起こりうることがら」は表がでるか、裏がでるかの２択と言って良いでしょう(コインが立つなどの事象は捨象します)。このとき、「表がでる」と「裏がでる」の2択に対して、それぞれ値1と0を割り当てます。表がでる＝1、裏がでる＝0です。そして、0か1を取る変数$x$を用意します。$(x \in \{0, 1\})$このようにして、「起こりうる事柄(表がでるか、裏が出るか)に割り当てている値(0, 1)を取る変数」として確率変数$x$が定義できました。
確率変数が定義できれば、あとは、確率分布を定義するだけです。今、確率変数$x$が0か１をとるので、例えば、表がでる確率を$1/3$,裏がでる確率を$2/3$とすれば、以下のように、「確率変数に対して、各々の値をとる確率を表したもの」$p(x)$を定義できますね！
$$ p(x) = 
    \begin{cases}
        {1/3 \ (x = 1)}\\
        {2/3 \ (x = 0)}
    \end{cases}
$$
以上より、ざっくり以下のような理解が得られます。確率変数は、確率的にその値が変動して決まる変数のこと、確率分布とは、確率変数を引数にとって、確率の公理を満たしながら、各値にその確率を割り振る関数である。
        
###### 例2. ランダムに日本人成人男性を１人ピックアップして測った身長の確率分布
確率変数になるのは、
    - 確率変数となるのは，身長$x$．この確率変数が正規分布に従うとする．
    
    $$
    x \sim N(\mu, \sigma^2) \\
    N(\mu, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^{2}}} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)
    $$
    
    - 正規分布は，平均$\mu$ を中心に，分散$\sigma^2$の分だけ裾野の広い(横に広がった)山のような形になる
    - 日本人成人男性だと，$\mu=168, \sigma^2 = (7.1)^2$だと推定されている．(ref．[政府統計](https://www.e-stat.go.jp/dbview?sid=0003224177) )
        
        ![ダウンロード (11).png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6d2d028b-16e4-4da1-8664-86c40589a6dd/ダウンロード_(11).png)
        

# 「機械学習」における「機械」とは何か？

### ここでは一旦，以下のように定義する

- 機械＝統計モデル

### 統計モデルとは何か？

- 決定論的な数理モデル
    - 変数間の関係性を方程式の形に落とせば，「数理モデル」と呼べる
    - 決定論的に決まる．入力が定まれば，必ず同じ値が出てくる．
- 統計モデル
    - 方程式に，[確率分布に従う変数](https://www.notion.so/c4f8ace8d5a043ffa4e6c1357b316605)が入っているものが「統計モデル」と呼べる
    - 確率的要素が入るため，毎回入力が同じでも，出力が異なる．

### 統計モデルの例＝線形回帰モデル

- ある日の平均気温$x$℃とその日のビール$y$本の売り上げに，以下のような関係が成り立つと仮定する
    
    $$
    y=\alpha x + \beta + \epsilon \\
    \epsilon \sim N(0, \sigma^2)
    $$
    
    - 式の意味：平均気温$x$を$\alpha$倍したものに対して，平均気温以外の要因(その日の天候，オリンピックなどのイベントなどなど)$\epsilon$が加わった結果，ビールの売り上げ$y$が生じる，
- 上記の方程式は統計モデルであると言える
    - その日の温度を入力として，出力をビール売り上げだとすると，入力が一定でも出力が異なってくる．これは$\epsilon$が正規分布に従うからである．
- $\alpha , \sigma, \beta$は，パラメタと呼ばれ，モデルのふるまいを決定する
    - $\alpha$が正であれば，気温があがればあがるほど，ビールがうれる．
    - 負であれば，気温があがればあがるほど，ビールがうれなくなる．
    - $\sigma^2$が大きければ大きいほど，気温以外の説明要因が大きいことがわかる．

# 機械が学習するとはどういうことなのか？

### ここでは一旦，以下のように定義する

- 機械が学習した＝統計モデルにおいて，**現実に観測されたデータ**からモデルの振る舞いを決定する**パラメタが決まった**．(あるいはデータ観測後のパラメタの分布がわかった)

### 例：線形モデル

- 過去の観測から，ビールの売り上げと気温のデータ$(x_i, y_i) (i=1, ..., N)$が得られたとする．(現実に観測されたデータ)
- これらのデータからモデルの振る舞いを決定するパラメタ$\alpha, \sigma$ を決定することが，機械学習である．

### 3つの異なる学習方法

①最尤法

②最大事後確率推定法

③ベイズ推定

---

# 学習方法①：最尤法

### アイデア・着想

- $\theta$によってパラメタライズされた統計モデル$p(x|\theta)$からデータ$\{x_1, x_2, ....,x_N\}$が得られたときに，どのように$\theta$を決める(=学習する)のが良いアイデアだろうか？
    - 得られたデータを最もよく説明する値$\hat \theta$を$\theta$の値とする
    - 最もよく説明するというのは，具体的にどういうことだろうか？
        - $p(x|\hat \theta)$からデータ${x_1, ...x_N}$が得られることが，他のどの候補値$\theta_1, \theta_2, .....$よりもあり得そう＝最尤法

### 例１)正規分布

- 統計モデル$p(x|\mu) = N(\mu, 1)$のパラメタ$\mu$を最尤法によって推定することを考える．
- データが$\{1, 1, 1, 3,-1,1\}$と得られた時に，どの$\mu$で説明するのが一番尤もらしいですか？
    
    ![unnamed.jpeg](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/adb8ce61-95ad-46bd-8dcb-e6a716d4b1e9/unnamed.jpeg)
    
- $\mu$を最尤法によって推定した結果は、データの算術平均となる。
    - 興味ある人いたら．
    
    ![unnamed.jpeg](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/762858c8-3cea-4b46-b3b8-63dbb73746b2/unnamed.jpeg)
    

### 理論

- 確率変数$x$が確率分布$p(x|\theta)$に従うとする．また，この確率分布からそれぞれ独立にデータ$\{x_1, x_2, ....,x_N\}$が得られたとする．このときパラメタ$\theta$を尤度関数$f(\{x_1, ...,x_N\} | \theta)$が最大値をとるようにパラメタ$\theta$を決定することを最尤法と呼ぶ．

$$
f(\{x_1,...,x_N\} | \theta) = \prod_{i=1}^{N}p(x_i| \theta) \\ 
\theta_{mle} = \underset{\theta}{argmax} f(\{x_1,...,x_N\} | \theta)
$$

### 例２)線形回帰

- 回帰モデル$y = \alpha x + \beta + \epsilon$のパラメタ$\alpha, \beta, \sigma^2$も正規分布の例と同様に求められる．
- $N(\mu, \sigma)$の形になってないじゃないか→なるように変形する．
    - $y$の生成メカニズムを考えると，$N(0, \sigma^2)$から生成された$\epsilon$に対して，**定数である$\alpha x + \beta$**が加わって，できるので，$y \sim N(\alpha x + \beta, \sigma^2)$
    - 同じく尤度関数を求め，それを各パラメータで微分すると以下のような式が導ける。
        
        $$
        \frac{\partial L}{\partial \alpha} = \frac{1}{\sigma^2}\sum_{i=1}^{N}x_i\left\{y_{i}-\left(\beta+\alpha x_{i}\right)\right\} \\
        \frac{\partial L}{\partial \beta} = \frac{1}{\sigma^2}\sum_{i=1}^{N}\left\{y_{i}-\left(\beta+\alpha x_{i}\right)\right\}
        $$
        
        - 詳細
            
            ![unnamed.jpeg](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d9ef036d-c1ec-41d2-b078-0dced95f117b/unnamed.jpeg)
            
        - 最小二乗法との関係(伝われ！！)
            
            線形モデルにおいて確率モデルとみなして，最尤法によってパラメタを推定した結果は，識別モデルとして最小二乗法としてパラメタを推定した結果と一致する．
            

# 学習方法②：最大事後確率推定法

### アイデア・着想＝最尤法の課題点から

- 得られたデータを説明すること=尤度を最大化することだけを目的にしているため，いわゆる過学習の問題が起きやすい方法
- 過学習とは?
    - すでに得られたデータ$\{x_1, ..., x_N\}$に対してかなりの予測精度を示し，未知のデータ$\{x_{N+1}, ..., x_{M}\}$を予測できなくなってしまう病
    - 例えば，テストの過去問$\{x_1, ..., x_N\}$やりすぎて，本番の試験の点数$\{x_{N+1}, ..., x_{M}\}$が取れなくなってしまう的な．
- 過学習を回避するためには？=最大事後確率推定法
    - すでに得られたデータに対する説明だけでなく，事前に人間の側が「この変数は，こういった分布に従うのはないか？」と仮定し，**「得られたデータに対する説明性能(尤度に対する説明)」＋「事前に設けた仮定に対する説明性能」の両方を最大化**させてパラメタを決定する．
    - コインの例→コインの表が出る確率$p$を推定しようとした時に，複数回のコイン投げで表がでたか裏がでたかのデータ$\{x_1, ..., x_N\}$が得られているとする．このデータだけで，$p$を推定しようとするのが，最尤法．そうではなくて，予め事前においた**仮定「コインの表と裏は同じぐらいの確率ででるのではないか？」とデータを一緒に説明**するのが最大事後確率推定法

### 準備：事前確率と事後確率

- **ここで少し思考の転換が必要！！！**
- 最尤法では，パラメタ$\theta$に対して唯一の真の値$\theta^*$が存在することを仮定していた．
- ここから先は，パラメタ$\theta$に関しても，何らかの確率分布$p(\theta)$に従うものと仮定する．
- このとき，事前確率と事後確率を以下のように定義する．
    - 人が設定する事前確率 = $p(\theta)$
    - データを観察した後という意味の事後確率 = $p(\theta | \{x_1, ..., x_N\})$
- 事後確率は以下のように，事前確率と尤度との積に比例する形で表現できる(ref.  ベイズの定理)
    - **~~事後確率の最大化は事前確率と尤度を同時に最大化**している事になる~~事後確率を最大化しようとすることは、尤度の最大化と事前確率の最大化のどちらも考慮にいれている

$$
p(\theta|\{x_1, ..., x_N\}) =\frac{p(\theta) f(\{x_1, ..., x_N\}|\theta)}{\prod_{i=1}^{N}p(x_i)} \\
\qquad \qquad \qquad \qquad \propto \underbrace {p(\theta)}_{事前確率} \underbrace {f(\{x_1, ..., x_N\}|\theta)}_{尤度}　　
$$

### 最大事後確率推定法

確率変数$x$が確率分布$p(x|\theta)$に従うとする．また，この確率分布からそれぞれ独立にデータ$\{x_1, x_2, ....,x_N\}$が得られたとする．このときパラメタ$\theta$を事後確率$p(\theta|\{x_1, ..., x_N\})$が最大値をとるようにパラメタ$\theta$を決定することを最大事後確率推定法と呼ぶ．

$$
p(\theta|\{x_1, ..., x_N\}) =\frac{p(\theta) f(\{x_1, ..., x_N\}|\theta)}{\prod_{i=1}^{N}p(x_i)} \\
\theta_{map}= \underset{\theta}{argmax} p(\theta|\{x_1, ..., x_N\}) 
$$

### 例) 線形回帰

- $y \sim N(\alpha x + \beta, \sigma^2)$
- $\theta = (\alpha, \beta)^{T}, \bold{x} = (x, 1)^{T}$とおくと、$y \sim N(\theta^{T}\bold{x}, \sigma^2)$
- $\theta$の事前分布を$N(0, \alpha^{-1}I)$とする。
    - つまり、パラメタは、ゼロに近い値を取りやすいと仮定する。
- 事前分布と尤度をもとに、事後分布を計算し、大数をとると以下の形になる。
    - $log(\theta | Y, X) = -\frac{\alpha}{2} ||\theta||^2 - \frac{1}{2 \sigma^2} ||\bold{y} - A\theta||^2 + constant$
    - $A \in \mathbb{R}^{N \times D}$は計画行列($i$行目が$\bold{x}_i$に対応する行列)
- 上の式が、最大化する目的関数($\theta$で微分してゼロとおく)
- **右辺の第一項**に注目すると、目的関数の最大化の過程で、$\theta$の値が大きくなるのを抑制されていることに気がつく→データに対する過剰な適合($\sim \theta$の値が極端に多くなること)を防いでいる。
- 計算した結果
    
    ![unnamed.jpeg](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/eb8147e9-1b1e-4010-a9db-2b2a79818001/unnamed.jpeg)
    
- 正則化との関係(伝われ！！)
    
    事前分布を各変数が無相関で平均が０の多変量正規分布と仮定したパラメタの最大事後確率推定は、リッジ回帰によるパラメタ推定の結果と一致する。事前分布にラプラス分布を仮定した場合、ラッソ回帰のパラメタ推定結果と一致する。
    

# 学習方法③：ベイズ推定法

### アイデア・着想＝最大事後確率推定法の課題点

- (尤度法も含めて)パラメタをただ１点に定めてしまうと，予測や推定のあいまいさ不完全さを表現できなくなる．
- 例，コインの表のでる確率$p$
    - コインを２回投げて，表１回，裏１回がでたことから$p$を推定する
    - コインを100回投げて，表50回，裏50回がでてことから$p$を推定する
        - どちらがより信頼性の高い$p$の推定だろうか？
        - 尤度法や最大事後確率推定方では，どちらも1/2(かその付近)の1点にパラメータを決め打ちしてしまい，推論の信頼性(逆に言えば推論の不確実性)を表現できない．
    - ベイズ推定は，この推論の不確実性への対処を可能にする．

### ベイズ推定における学習とは？

- 事後分布$p(\theta | \{x_1, ..., x_N\})$の推定を持って，「学習を終えた」とみなす．
- 次に出るデータを予測したければ、予測分布を計算する。
    
    $p(x_{new}|\{x_1, ...,x_n\}) = \int p(\theta|\{x_1, ...,x_n\})p(x_{new}|\theta)d\theta$
    

### 例)コイン投げ

- コイン投げで表がでる確率を$p$とおき、表がでる事象を$x=1$裏がでる事象を$x=0$とおく。
- 確率密度関数は、$p(x|p) = Bern(x|p)$。つまり、$x$がベルヌーイ分布に従うと仮定する。
- 最初２回のコイン投げで、$X_1=\{1, 1\}$が得られ、次に5回コインが投げられたとき$X_2 =\{0, 0, 0, 0,0 ,0\}$が出たとする。(明らかに裏がでやすいコインである。)
- ここで、我々は最初の２回のコイン投げを知った後で、次の５回どのような目が出そうかを予測するゲームに参加しているとする。($X_2$を知らない。)
    - 最尤法を採用した場合。
        - [導出は割愛](http://www-ikn.ist.hokudai.ac.jp/~yasuhiro-suzu/Bernoulli%20Distributin.pdf)しますが、$p$を最尤推定した結果は、(x=1となった回数)/(試行回数)
        - 2回とも表が出ているので$p=1$。つまり、必ず表がでるコインである、次の５回も表がでつづけるに違いない。
    - ベイズ推定法を採用した場合。
        - $p$の事前分布として、ベータ分布$Beta(\alpha, \beta)$をおく。
        - $\alpha, \beta$の値は、$\alpha=2, \beta=2$とする。(以下のような分布になる。)
            
            ![ダウンロード (15).png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/b17239ff-48b0-4f17-8a1b-8abe96a0d1aa/ダウンロード_(15).png)
            
        - [導出は割愛](https://ai-trend.jp/basic-study/bayes/beta-bernoulli-distribution/)しますが、データ$X_1$が得られたあとの$\alpha, \beta$は以下のようになる。$\gamma$は成功回数。(これで事後分布が推定された＝学習が終わった)
        
        $$
        \alpha = \alpha + \gamma =2 + 2 = 4\\
        \beta = \beta + (n - \gamma) = 2 + 0 = 2
        $$
        
        ![ダウンロード (16).png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/d1677e40-0557-49f0-a6e9-1d896f1c6699/ダウンロード_(16).png)
        
        - 事後分布を観察すると、$p=0.78$ぐらいのところに山のテッペンがきており、表が出やすいコインであることがわかる。しかし、**最尤推定と異なり,$p=1$**として決め打ちすることがないため、次の５回の予測は、裏がでることも想定した予測になる。

# 参考文献兼おすすめ書籍

個人的に、機械学習の基礎となるベイズ統計理論を理解するために役立ちそうな文献・書籍を紹介しておきます！！

- 入門　統計解析法、永田靖
    - [https://www.juse-p.co.jp/products/view/23](https://www.juse-p.co.jp/products/view/23)
    - ベイズ統計を学ぶ前に、中心極限定理や大数の法則、検定論などのフィッシャーが展開した統計学を学んでおくのがセオリーだったりします。数理的に難しいところに踏み込まずに最低限の部分を勉強できた書籍でした〜。
- ベイズ推論による機械学習入門　須山敦志
    - [https://www.kspub.co.jp/book/detail/1538320.html](https://www.kspub.co.jp/book/detail/1538320.html)
    - この発表の内容は、この本の内容をベースにしています。
- 変分推論の理論 pdf 宮本祟
    - [https://www.ccn.yamanashi.ac.jp/~tmiyamoto/img/variational_bayes1.pdf](https://www.ccn.yamanashi.ac.jp/~tmiyamoto/img/variational_bayes1.pdf)
    - 「ベイズ推論による機械学習入門」をさらにコンパクトにした内容です。

---

- Pattern Recognition And Machine Learning 　ビショップ
    - [http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop - Pattern Recognition And Machine Learning - Springer 2006.pdf](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf)
    - ベイズ統計軸にした機械学習研究者の必読書になっているような本だと思います。
- Auto-Encoding Variational Bayes 　　P.Kingma
    - [https://arxiv.org/abs/1312.6114](https://arxiv.org/abs/1312.6114)
    - この論文は、ベイズ推論における事後分布の推論をニューラルネットワークの高い表現能力に任せるという発想で有名です。
    
    「事後確率の最大化は事前確率と尤度を同時に最大化している事になる」これは「事前確率の最大」と「尤度の最大」が同時に起こるように読めるのですが、そういう意味ですか。
